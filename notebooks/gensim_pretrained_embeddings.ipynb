{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gensim_pretrained_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasgneccoh/FNC_nlp_project/blob/main/notebooks/gensim_pretrained_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msC270S-YNXF"
      },
      "source": [
        "# Imports and initial definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKHAf9Ulvg6i"
      },
      "source": [
        "## Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO-7SSqJAWvQ"
      },
      "source": [
        "import os\n",
        "%cd /content\n",
        "!git clone https://github.com/lucasgneccoh/FNC_nlp_project.git\n",
        "\n",
        "os.chdir(\"/content/FNC_nlp_project\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WfoSBA4UHZA"
      },
      "source": [
        "## Install and import gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JvJQqhUJlnG",
        "outputId": "09d27854-c803-4d53-9903-00e6c817c645"
      },
      "source": [
        "!pip install gensim==4.0.0b\n",
        "import gensim\n",
        "import gensim.downloader as api"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim==4.0.0b\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/47/16e2e4f34ec7534db21facf505c5a17e3ba10cbce72f675721277628d454/gensim-4.0.0b0-cp37-cp37m-manylinux1_x86_64.whl (24.0MB)\n",
            "\u001b[K     |████████████████████████████████| 24.0MB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.0b) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.0b) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.0b) (5.0.0)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.0.0b0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3auhyrn_YmOK"
      },
      "source": [
        "# Word2vec trained with Google news\n",
        "We would like to work with this pretrained **word2vec** model. \n",
        "\n",
        "Here we load the model and test it in simple examples\n",
        "\n",
        "For more information on the model, see the [original google site](https://code.google.com/archive/p/word2vec/) or the [gensim repository](https://github.com/RaRe-Technologies/gensim-data#models)\n",
        "\n",
        "From our tests, we liked this model because it seems to really capture the semantics of the words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p6drOKl52qp"
      },
      "source": [
        "Sometimes the download using the `gensim` api is not possible and throws a `ConnectionResetError`. In that case, you can download the original Google news model from the [original site](https://code.google.com/archive/p/word2vec/) and load it.\n",
        "The following cell does that in the Google Colab machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgOFREzv_VFA",
        "outputId": "8f7ecbfd-951c-4e13-96b9-44daa781ba7e"
      },
      "source": [
        "\"\"\" *** This cell only works in Google Colab ***\n",
        "    It saves the file in the temporal machine using wget, which is much faster\n",
        "    than the download using the gensim api\n",
        "    If you are not using Google Colab, then simply download the file yourself\n",
        "    and get the path to load the word vectors into the variable path_google_w2v\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cwd = os.getcwd()\n",
        "%cd /content\n",
        "!mkdir downloaded_embeddings\n",
        "%cd /content/downloaded_embeddings\n",
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "path_google_w2v = \"/content/downloaded_embeddings/GoogleNews-vectors-negative300.bin.gz\"\n",
        "\n",
        "%cd $cwd\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-30 01:01:49--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.78.166\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.78.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  66.4MB/s    in 25s     \n",
            "\n",
            "2021-04-30 01:02:14 (64.0 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oTxkjh85L3r",
        "outputId": "57e32709-3a30-4ab8-e220-4daf2028a351"
      },
      "source": [
        "%%time\n",
        "w2v_google = gensim.models.KeyedVectors.load_word2vec_format(path_google_w2v, binary=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 2s, sys: 3.07 s, total: 1min 5s\n",
            "Wall time: 1min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us9juk0fEMjt"
      },
      "source": [
        "Here is the code if you want to try using the `gensim` api. \n",
        "\n",
        "NOTE: This will take time, and it weights 1.5G"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvD5wZPPELfi"
      },
      "source": [
        "%%time\n",
        "\"\"\" Download the w2v model (1662.8 MB) \n",
        "\"\"\"\n",
        "w2v_google = api.load('word2vec-google-news-300', return_path=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO5ZweFFEUN0"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FdJiykstcts",
        "outputId": "2b51b8a7-5604-4a16-d5a3-9b84f49c5d33"
      },
      "source": [
        "print(f\"Total number of unique words in Google corpus: {len(w2v_google.key_to_index)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of unique words in Google corpus: 3000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tuG1RvB_6de",
        "outputId": "60bd9dd3-3366-493c-b339-88a4f4005916"
      },
      "source": [
        "\"\"\" Here we want to do 'most similar' queries for some words\n",
        "\"\"\"\n",
        "to_check = ['woman', 'man', 'strong', 'america', 'china', 'weak', 'bank', 'hard', 'easy', 'hoax']\n",
        "for w in to_check: \n",
        "    print(\"Similar to {}: {}\".format(w, w2v_google.most_similar(positive=[w], topn=3)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similar to woman: [('man', 0.7664012908935547), ('girl', 0.7494640946388245), ('teenage_girl', 0.7336829304695129)]\n",
            "Similar to man: [('woman', 0.7664012908935547), ('boy', 0.6824871301651001), ('teenager', 0.6586930155754089)]\n",
            "Similar to strong: [('solid', 0.7009872198104858), ('stong', 0.6510646939277649), ('robust', 0.6499253511428833)]\n",
            "Similar to america: [('american', 0.7169357538223267), ('americans', 0.7042055130004883), ('europe', 0.6617692112922668)]\n",
            "Similar to china: [('dinnerware', 0.6587947607040405), ('crockery', 0.6426128149032593), ('porcelain', 0.6392655372619629)]\n",
            "Similar to weak: [('weaker', 0.7303191423416138), ('Weak', 0.6872072815895081), ('sluggish', 0.6702948808670044)]\n",
            "Similar to bank: [('banks', 0.7440759539604187), ('banking', 0.690161406993866), ('Bank', 0.6698698401451111)]\n",
            "Similar to hard: [('harder', 0.6780325174331665), ('Hard', 0.6441888809204102), ('tough', 0.6342882513999939)]\n",
            "Similar to easy: [('easier', 0.6639506220817566), ('easiest', 0.6109094023704529), ('simple', 0.5990299582481384)]\n",
            "Similar to hoax: [('hoaxes', 0.6636695265769958), ('devotional_inscription', 0.6494374871253967), ('Hoax', 0.6456077098846436)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rir1dLpNT1qa",
        "outputId": "ff0c13b2-3a33-4680-f151-ac6dda6df02a"
      },
      "source": [
        "\"\"\" Here we want to do 'most similar' queries using\n",
        "    positive and negative words\n",
        "\"\"\"\n",
        "pos = [['woman'], ['man'], ['china'], ['america']]\n",
        "neg = [['man'], ['woman'], ['america'], ['china']]\n",
        "\n",
        "for p, n in zip(pos, neg):\n",
        "    print(f\"+: {p}, -: {n}\")\n",
        "    print(*w2v_google.most_similar(positive = p, negative = n, topn=5))\n",
        "    print('-'*50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+: ['woman'], -: ['man']\n",
            "('she', 0.45412716269493103) ('her', 0.39712801575660706) ('Certified_Nurse_Midwife', 0.3824717402458191) ('Ms.', 0.37514764070510864) ('silicone_gel_implant', 0.3704040050506592)\n",
            "--------------------------------------------------\n",
            "+: ['man'], -: ['woman']\n",
            "('Shaun_Maloney_Aiden_McGeady', 0.35027220845222473) ('tactically_adept', 0.3487197160720825) ('Matt_Bramald', 0.3400961458683014) ('strongside_LB', 0.337636798620224) ('newboy', 0.33329278230667114)\n",
            "--------------------------------------------------\n",
            "+: ['china'], -: ['america']\n",
            "('dinnerware', 0.6009308695793152) ('tableware', 0.5477373600006104) ('flatware', 0.533893346786499) ('crockery', 0.5331457853317261) ('vases', 0.5137503743171692)\n",
            "--------------------------------------------------\n",
            "+: ['america'], -: ['china']\n",
            "('americans', 0.3803958296775818) ('nebraska', 0.3545896112918854) ('texas', 0.3540230393409729) ('american', 0.34462225437164307) ('atlanta', 0.3441712558269501)\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1uOV4EAC1Nu"
      },
      "source": [
        "\"\"\" We are done, free memory \n",
        "\"\"\"\n",
        "del w2v_google"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy2tlYUFJhkc"
      },
      "source": [
        "# FastText\n",
        "Another interesting option would be the pre traines **fasText** using wiki news\n",
        "\n",
        "See the [gensim repository](https://github.com/RaRe-Technologies/gensim-data#models) for more information on the available models and the [fast text site](https://fasttext.cc/docs/en/english-vectors.html) for details on this **fastText** model.\n",
        "\n",
        "From the examples and tests we did, this model seems to relate words based more on their syntax than on their semantics. We think the Google News **word2vec** was superior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vrU9CNb7dP3"
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zoq8e-AlEmEj"
      },
      "source": [
        "The following cell downloads the **fastText** vectors in the Google Colab machine "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR52dDQ6DDLU"
      },
      "source": [
        "cwd = os.getcwd()\n",
        "%cd /content/downloaded_embeddings\n",
        "!wget -c \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip\"\n",
        "!unzip \"wiki-news-300d-1M-subword.vec.zip\"\n",
        "path_ft_facebook = \"/content/wiki-news-300d-1M-subword.vec\"\n",
        "\n",
        "%cd $cwd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IE821OcEgQU",
        "outputId": "d069a42b-eeac-43d9-b85b-509a10113cae"
      },
      "source": [
        "%%time\n",
        "ft_facebook = gensim.models.KeyedVectors.load_word2vec_format(path_ft_facebook, binary=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 17s, sys: 10.4 s, total: 5min 27s\n",
            "Wall time: 5min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV13KyF3Eik0"
      },
      "source": [
        "Again, here is the code to use the `gensim` api"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS3x6GsJfydr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe02601-d0ee-4820-baf2-877741389424"
      },
      "source": [
        "%%time\n",
        "ft_facebook = api.load('fasttext-wiki-news-subwords-300',return_path=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n",
            "CPU times: user 10min 37s, sys: 44.2 s, total: 11min 21s\n",
            "Wall time: 12min 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyC4KGrwWJi0",
        "outputId": "18593b93-d4ca-458a-9788-1a22ddb307de"
      },
      "source": [
        "\"\"\" Again 'most similar' queries for some words to compare \n",
        "    against the Google news word2vec\n",
        "\"\"\"\n",
        "to_check = ['woman', 'man', 'strong', 'america', 'china', 'weak', 'bank', 'hard', 'easy', 'hoax']\n",
        "for w in to_check: \n",
        "    ans = ft_facebook.most_similar(positive=[w], topn=3)\n",
        "    print(\"Similar to {} : {}\".format(w, ans))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similar to woman : [('man', 0.8119728565216064), ('woman--', 0.7959333062171936), ('lady', 0.775004506111145)]\n",
            "Similar to man : [('woman', 0.8119728565216064), ('man--', 0.73244309425354), ('man--and', 0.7232114672660828)]\n",
            "Similar to strong : [('weak', 0.7990458607673645), ('strong-', 0.7753340005874634), ('strongish', 0.7710019946098328)]\n",
            "Similar to america : [('americas', 0.7932907938957214), ('america.', 0.7870585322380066), ('usa', 0.7484654784202576)]\n",
            "Similar to china : [('china.', 0.6974452137947083), ('chinas', 0.6943490505218506), ('porcelain', 0.6891270875930786)]\n",
            "Similar to weak : [('strong', 0.7990459203720093), ('weaker', 0.7790804505348206), ('feeble', 0.7767082452774048)]\n",
            "Similar to bank : [('banks', 0.8217378854751587), ('bank-', 0.7699344754219055), ('banking', 0.7486941814422607)]\n",
            "Similar to hard : [('harder', 0.7852727174758911), ('tough', 0.7670266032218933), ('hards', 0.7339461445808411)]\n",
            "Similar to easy : [('straightforward', 0.7886142730712891), ('quick', 0.7723290324211121), ('easier', 0.7714544534683228)]\n",
            "Similar to hoax : [('hoaxing', 0.8121007084846497), ('hoaxes', 0.8028857707977295), ('hoax.', 0.7993180751800537)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqC5q_LbxlYE",
        "outputId": "75a0edbe-7ce4-448c-958b-22da57887e28"
      },
      "source": [
        "\"\"\" Here we want to do 'most similar' queries using\n",
        "    positive and negative words\n",
        "\"\"\"\n",
        "pos = [['woman'], ['man'], ['china'], ['america']]\n",
        "neg = [['man'], ['woman'], ['america'], ['china']]\n",
        "\n",
        "for p, n in zip(pos, neg):\n",
        "    print(f\"+: {p}, -: {n}\")\n",
        "    print(*ft_facebook.most_similar(positive = p, negative = n, topn=5))\n",
        "    print('-'*50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+: ['woman'], -: ['man']\n",
            "('WCJF', 0.3708224296569824) ('woman-to-woman', 0.35294315218925476) ('Němcová', 0.3509597182273865) ('OBGYN', 0.3495628237724304) ('OB-GYNs', 0.3440229892730713)\n",
            "--------------------------------------------------\n",
            "+: ['man'], -: ['woman']\n",
            "('guvnor', 0.3640994131565094) ('roght', 0.3340262472629547) ('brillig', 0.3283083438873291) ('genuis', 0.3235689103603363) ('Guvnor', 0.3225095272064209)\n",
            "--------------------------------------------------\n",
            "+: ['china'], -: ['america']\n",
            "('porcelain', 0.47698038816452026) ('porcelains', 0.4386729300022125) ('Jingdezhen', 0.43594178557395935) ('vases', 0.4217434525489807) ('crockery', 0.4191197156906128)\n",
            "--------------------------------------------------\n",
            "+: ['america'], -: ['china']\n",
            "('america.', 0.40032851696014404) ('americas', 0.32730168104171753) ('americans', 0.3270949125289917) ('americans.', 0.32590192556381226) ('american.', 0.31294891238212585)\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}